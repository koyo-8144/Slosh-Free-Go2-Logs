Try adding rot_y as observation space.

"tracking_lin_vel": 2.0,
"tracking_ang_vel": 1.0,
"lin_vel_z": -2.0,
"ang_vel_xy": -0.05,
"base_height": -30.0,
"orientation": -0.1,
"collision": -1.0,
"dof_pos_limits": -10.0,
"torques": -1e-5,
"dof_acc": -2.5e-7,
"action_rate": -0.01,
"slosh_free": 0.015,

"num_commands": 3,
"num_obs": 46,
"num_privileged_obs": 49, # num_obs + base_lin_vel
"only_positive_rewards": True,
"linvel_update_freq": 10,
"alpha": 0.9

Learning rate update from KL:
rate -> 1.025
minumum -> 5.25e-4

No acc profile resample

Result:
I tried to run this three times and mean reward did not go over 0.0 but it did on 4th times, as a report.
Stopped around 7k due to NaN.
Not much difference without rot_y in observation.

Plan:
Learning rate update from KL:
rate -> 1.5
minumum -> 3.3e-4