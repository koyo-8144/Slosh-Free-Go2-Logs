reduce feet_air_time to 0.5 + reduce linvel_update_freq to 1 for slosh_free 

"tracking_lin_vel": 1.0,
"tracking_ang_vel": 0.5,
"lin_vel_z": -2.0,
"ang_vel_xy": -0.05,
"base_height": -30.0,
"orientation": -0.1,
"collision": -1.0,
"dof_pos_limits": -10.0,
"torques": -1e-5,
"dof_acc": -2.5e-7,
"action_rate": -0.01,
"feet_air_time": 0.5, 
"slosh_free": 1.0,

"num_commands": 3,
"num_obs": 45,
"num_privileged_obs": 48, # num_obs + base_lin_vel
"only_positive_rewards": True,
"linvel_update_freq": 1,

Learning rate update froom KL: 
if kl_mean > self.desired_kl * 2.0:
    self.learning_rate = max(1e-5, self.learning_rate / 1.05)
elif kl_mean < self.desired_kl / 2.0 and kl_mean > 0.0:
    self.learning_rate = min(1e-2, self.learning_rate * 1.05)


Result:
reduce feet_air_time to 0.5 + reduce linvel_update_freq to 1 for slosh_free 
learning rate reached to bottom and unstabilise the reward curve but get back to higher learning rate.
learning rate fluctuated -> reward curve as well.
Go2 stil did not notice slosh_free.

Plan:
Learning rate update froom KL: 
if kl_mean > self.desired_kl * 2.0:
    self.learning_rate = max(1e-5, self.learning_rate / 1.01)
elif kl_mean < self.desired_kl / 2.0 and kl_mean > 0.0:
    self.learning_rate = min(1e-2, self.learning_rate * 1.01)

#"tracking_lin_vel": 2.0,
#"tracking_ang_vel": 1.0,
#"ax": 1.0,
#"az": 1.0,