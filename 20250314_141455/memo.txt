Learning rate update from KL -> 1.05 and rremove feet_air_time and  "tracking_lin_vel": 2.0 and "tracking_ang_vel": 1.0,

"tracking_lin_vel": 2.0,
"tracking_ang_vel": 1.0,
"lin_vel_z": -2.0,
"ang_vel_xy": -0.05,
"base_height": -30.0,
"orientation": -0.1,
"collision": -1.0,
"dof_pos_limits": -10.0,
"torques": -1e-5,
"dof_acc": -2.5e-7,
"action_rate": -0.01,
"slosh_free": 1.0,

"num_commands": 3,
"num_obs": 45,
"num_privileged_obs": 48, # num_obs + base_lin_vel
"only_positive_rewards": True,
"linvel_update_freq": 1,

Learning rate update froom KL: 
if kl_mean > self.desired_kl * 2.0:
    self.learning_rate = max(1e-5, self.learning_rate / 1.05)
elif kl_mean < self.desired_kl / 2.0 and kl_mean > 0.0:
    self.learning_rate = min(1e-2, self.learning_rate * 1.05)


Result:
learning rate dropped around 1k and messed up.
Better to create constant leanring rate decay rather than learning rate decay base on KL divergence?

Plan:
Learning rate update froom KL: 
if kl_mean > self.desired_kl * 2.0:
    self.learning_rate = max(5e-4, self.learning_rate / 1.05)
elif kl_mean < self.desired_kl / 2.0 and kl_mean > 0.0:
    self.learning_rate = min(1e-2, self.learning_rate * 1.05)


#"ax": 5.0,
#"az": 1.0,